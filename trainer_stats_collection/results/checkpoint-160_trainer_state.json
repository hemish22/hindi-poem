{
  "best_metric": 0.23122679455445544,
  "best_model_checkpoint": "./results/checkpoint-160",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 160,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.125,
      "grad_norm": 6.964152812957764,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 2.3267,
      "step": 10
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.532618522644043,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 2.2867,
      "step": 20
    },
    {
      "epoch": 0.375,
      "grad_norm": 3.991323232650757,
      "learning_rate": 3e-06,
      "loss": 2.2839,
      "step": 30
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.9814693927764893,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.2449,
      "step": 40
    },
    {
      "epoch": 0.625,
      "grad_norm": 3.8528685569763184,
      "learning_rate": 5e-06,
      "loss": 2.1414,
      "step": 50
    },
    {
      "epoch": 0.75,
      "grad_norm": 4.371201992034912,
      "learning_rate": 6e-06,
      "loss": 2.1253,
      "step": 60
    },
    {
      "epoch": 0.875,
      "grad_norm": 4.040008068084717,
      "learning_rate": 7.000000000000001e-06,
      "loss": 2.1072,
      "step": 70
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.638184070587158,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.9829,
      "step": 80
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.3375,
      "eval_f1": 0.1703271028037383,
      "eval_loss": 2.0290439128875732,
      "eval_precision": 0.11390625000000001,
      "eval_recall": 0.3375,
      "eval_runtime": 0.3981,
      "eval_samples_per_second": 803.818,
      "eval_steps_per_second": 25.119,
      "step": 80
    },
    {
      "epoch": 1.125,
      "grad_norm": 19.53318214416504,
      "learning_rate": 9e-06,
      "loss": 2.0756,
      "step": 90
    },
    {
      "epoch": 1.25,
      "grad_norm": 5.445204734802246,
      "learning_rate": 1e-05,
      "loss": 2.0971,
      "step": 100
    },
    {
      "epoch": 1.375,
      "grad_norm": 3.9679195880889893,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 1.9573,
      "step": 110
    },
    {
      "epoch": 1.5,
      "grad_norm": 4.642080307006836,
      "learning_rate": 1.2e-05,
      "loss": 2.1127,
      "step": 120
    },
    {
      "epoch": 1.625,
      "grad_norm": 2.5377004146575928,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 2.0763,
      "step": 130
    },
    {
      "epoch": 1.75,
      "grad_norm": 2.8802385330200195,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 2.1142,
      "step": 140
    },
    {
      "epoch": 1.875,
      "grad_norm": 4.960814476013184,
      "learning_rate": 1.5e-05,
      "loss": 2.0095,
      "step": 150
    },
    {
      "epoch": 2.0,
      "grad_norm": 4.45692777633667,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.8603,
      "step": 160
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.378125,
      "eval_f1": 0.23122679455445544,
      "eval_loss": 1.9896533489227295,
      "eval_precision": 0.1908502252252252,
      "eval_recall": 0.378125,
      "eval_runtime": 0.3796,
      "eval_samples_per_second": 842.956,
      "eval_steps_per_second": 26.342,
      "step": 160
    }
  ],
  "logging_steps": 10,
  "max_steps": 400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 153931023267840.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
